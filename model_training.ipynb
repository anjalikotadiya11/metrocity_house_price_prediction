{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baf57ab7-1fcb-4473-ac6c-38ac11e47b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded: (14528, 9)\n",
      "Cleaning Price Column...\n",
      "Price cleaning complete. Rows retained: 14528/14528\n",
      "Attempting to extract city from neighborhood...\n",
      "Injecting dummy rows for missing cities: {'Ahmedabad'}\n",
      "Encoding Cities...\n",
      "City columns created: ['city_Ahmedabad', 'city_Bangalore', 'city_Chennai', 'city_Delhi', 'city_Hyderabad', 'city_Kolkata', 'city_Mumbai', 'city_None', 'city_Pune']\n",
      "Total Features: 17\n",
      "Training Model...\n",
      "R2 Score: 0.37\n",
      "Training Complete. Artifacts saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "import re\n",
    "import joblib\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "print(\"Loading data...\")\n",
    "try:\n",
    "    df = pd.read_csv('real_estate_data.csv')\n",
    "    print(f\"Data loaded: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'real_estate_data.csv' not found.\")\n",
    "\n",
    "# --- 2. Standardize & Rename Columns ---\n",
    "df.columns = df.columns.str.lower().str.strip().str.replace(' ', '_')\n",
    "\n",
    "rename_map = {\n",
    "    'price': 'price',\n",
    "    'total_area': 'area_sqft',\n",
    "    'area': 'area_sqft',\n",
    "    'sqft': 'area_sqft',\n",
    "    'location': 'neighborhood',\n",
    "    'bhk': 'beds',\n",
    "    'bedroom': 'beds',\n",
    "    'bed': 'beds',\n",
    "    'bath': 'baths',\n",
    "    'bathroom': 'baths',\n",
    "    'bathrooms': 'baths',\n",
    "    'balcony': 'balcony',\n",
    "    'parking': 'parking',\n",
    "    'car_parking': 'parking',\n",
    "    'floor': 'floor',\n",
    "    'total_floors': 'total_floors',\n",
    "    'status': 'status',\n",
    "    'availability': 'status'\n",
    "}\n",
    "df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "# Handle potential duplicate price columns\n",
    "if 'raw_price' not in df.columns and 'price' in df.columns:\n",
    "    df['raw_price'] = df['price']  # Keep original for reference if needed\n",
    "\n",
    "# --- 3. ROBUST PRICE CLEANING (Moved to Top) ---\n",
    "# We clean price FIRST to avoid errors when calculating mean later\n",
    "def clean_price(x):\n",
    "    if pd.isna(x): return np.nan\n",
    "    # Ensure string format\n",
    "    x = str(x).upper().strip()\n",
    "    # Remove currency symbols and commas\n",
    "    x = x.replace('â‚¹', '').replace(',', '').replace('INR', '').strip()\n",
    "    \n",
    "    try:\n",
    "        multiplier = 1\n",
    "        if 'CR' in x:\n",
    "            multiplier = 10000000\n",
    "            x = x.replace('CR', '').strip()\n",
    "        elif 'L' in x: \n",
    "            multiplier = 100000\n",
    "            x = x.replace('LACS', '').replace('LAC', '').replace('L', '').strip()\n",
    "        elif 'K' in x:\n",
    "            multiplier = 1000\n",
    "            x = x.replace('K', '').strip()\n",
    "            \n",
    "        # Use Regex to find the number part (e.g., extracts '1.99' from '1.99')\n",
    "        match = re.search(r\"[\\d\\.]+\", x)\n",
    "        if match:\n",
    "            clean_val = float(match.group())\n",
    "            return clean_val * multiplier\n",
    "        else:\n",
    "            return np.nan\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "print(\"Cleaning Price Column...\")\n",
    "# Clean the 'price' column\n",
    "# We prioritize 'raw_price' if it exists (original string), else clean 'price' directly\n",
    "col_to_clean = 'raw_price' if 'raw_price' in df.columns else 'price'\n",
    "df['price'] = df[col_to_clean].apply(clean_price)\n",
    "\n",
    "# Drop rows where price couldn't be cleaned\n",
    "initial_count = len(df)\n",
    "df.dropna(subset=['price'], inplace=True)\n",
    "print(f\"Price cleaning complete. Rows retained: {len(df)}/{initial_count}\")\n",
    "\n",
    "\n",
    "# --- 4. City Column Handling ---\n",
    "target_cities = ['Mumbai', 'Bangalore', 'Chennai', 'Delhi', 'Pune', 'Hyderabad', 'Ahmedabad', 'Kolkata']\n",
    "\n",
    "# Function to extract city from neighborhood/address string\n",
    "def extract_city(address):\n",
    "    if pd.isna(address): return None\n",
    "    address = str(address).lower()\n",
    "    for city in target_cities:\n",
    "        if city.lower() in address:\n",
    "            return city\n",
    "    return None\n",
    "\n",
    "# If 'city' missing, try to rename or extract\n",
    "if 'city' not in df.columns:\n",
    "    possible_city = [c for c in df.columns if 'city' in c or 'address' in c]\n",
    "    if possible_city:\n",
    "        df.rename(columns={possible_city[0]: 'city'}, inplace=True)\n",
    "    elif 'neighborhood' in df.columns:\n",
    "        print(\"Attempting to extract city from neighborhood...\")\n",
    "        df['city'] = df['neighborhood'].apply(extract_city)\n",
    "\n",
    "# If still missing, create synthetic city distribution for testing\n",
    "if 'city' not in df.columns or df['city'].isnull().sum() > len(df) * 0.8:\n",
    "    print(\"WARNING: No valid 'city' column found. Creating synthetic city distribution for testing.\")\n",
    "    df['city'] = np.random.choice(target_cities, size=len(df))\n",
    "\n",
    "# Normalize city names\n",
    "if 'city' in df.columns:\n",
    "    df['city'] = df['city'].astype(str).str.title().str.strip()\n",
    "    \n",
    "    # Ensure ALL target cities are present (Inject dummies)\n",
    "    # Now safe because df['price'] is numeric\n",
    "    mean_price = df['price'].mean()\n",
    "    \n",
    "    missing_cities = set(target_cities) - set(df['city'].unique())\n",
    "    if missing_cities:\n",
    "        print(f\"Injecting dummy rows for missing cities: {missing_cities}\")\n",
    "        dummy_rows = []\n",
    "        for city in missing_cities:\n",
    "            dummy_rows.append({\n",
    "                'city': city, \n",
    "                'price': mean_price, \n",
    "                'area_sqft': 1000, \n",
    "                'beds': 2, \n",
    "                'baths': 2\n",
    "            })\n",
    "        df = pd.concat([df, pd.DataFrame(dummy_rows)], ignore_index=True)\n",
    "\n",
    "# --- 5. Impute Missing Values ---\n",
    "numeric_cols = ['area_sqft', 'baths', 'beds', 'balcony', 'parking', 'floor', 'total_floors']\n",
    "for col in numeric_cols:\n",
    "    if col not in df.columns:\n",
    "        df[col] = 0\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "\n",
    "# Status Handling\n",
    "if 'status' in df.columns:\n",
    "    df['status_ready'] = df['status'].apply(lambda x: 1 if 'ready' in str(x).lower() else 0)\n",
    "else:\n",
    "    df['status_ready'] = 1\n",
    "\n",
    "df.dropna(subset=['price', 'area_sqft'], inplace=True)\n",
    "\n",
    "# --- 6. Outlier Removal ---\n",
    "def remove_outliers(df, col):\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "\n",
    "df = remove_outliers(df, 'price')\n",
    "df = remove_outliers(df, 'area_sqft')\n",
    "\n",
    "# --- 7. Feature Engineering (One-Hot Encoding) ---\n",
    "print(\"Encoding Cities...\")\n",
    "df = pd.get_dummies(df, columns=['city'], prefix='city', drop_first=False)\n",
    "\n",
    "# Verify city columns exist\n",
    "city_cols_check = [c for c in df.columns if 'city_' in c]\n",
    "print(f\"City columns created: {city_cols_check}\")\n",
    "\n",
    "# --- 8. Define Features & Scale ---\n",
    "city_cols = [c for c in df.columns if 'city_' in c]\n",
    "features = ['area_sqft', 'baths', 'beds', 'balcony', 'parking', 'floor', 'total_floors', 'status_ready'] + city_cols\n",
    "\n",
    "print(f\"Total Features: {len(features)}\")\n",
    "\n",
    "X = df[features].copy()\n",
    "y = df['price']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scale_cols = ['area_sqft', 'baths', 'beds', 'balcony', 'parking', 'floor', 'total_floors']\n",
    "X[scale_cols] = scaler.fit_transform(X[scale_cols])\n",
    "\n",
    "# --- 9. Train & Save ---\n",
    "print(\"Training Model...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"R2 Score: {r2_score(y_test, y_pred):.2f}\")\n",
    "\n",
    "joblib.dump(model, 'house_price_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "with open('feature_columns.txt', 'w') as f:\n",
    "    f.write(','.join(features))\n",
    "\n",
    "print(\"Training Complete. Artifacts saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d84379-95a6-42bf-bc6f-82c67dae83ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
